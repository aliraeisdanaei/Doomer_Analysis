{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Data/doomer_scraped_29_10_2022.json\",lines=True)\n",
    "df = df.dropna(subset=['body'])\n",
    "\n",
    "\n",
    "df['tokenized'] = df['body'].astype(str).str.lower().str.split(\" \")\n",
    "df = df.explode('tokenized')\n",
    "freqs = df['tokenized'].value_counts().to_dict()\n",
    "newfreqs = {k:v for k,v in freqs.items() if k not in STOPWORDS}\n",
    "\n",
    "\n",
    "def clean_text(df):\n",
    "    punc = re.compile(r\"[\\n,!\\?\\’'\\+:\\\"\\.\\$&@#/\\(\\)\\[\\]\\|\\{\\}]\")\n",
    "    nonwords = re.compile('^[^a-zA-Z0-9]+$')\n",
    "    links = re.compile(r\"https\")\n",
    "    \n",
    "    df['body'] = df['body'].str.lower().replace('\\n','',regex=True).str.replace('’',\"'\",regex=True).str.replace(punc,'',regex=True).str.strip()\n",
    "    df = df[~df['body'].str.contains(links)]\n",
    "    df = df[~df['body'].str.contains(nonwords)]\n",
    "    df = df[df['body']!='']\n",
    "    df['tokenized'] = df['body'].str.split(' ')\n",
    "    return df\n",
    "\n",
    "def freqs(df):\n",
    "    \n",
    "    df = df.explode('tokenized')\n",
    "    freqs = df['tokenized'].value_counts().to_dict()\n",
    "    STOPWORDS.update({punc.sub('',x) for x in STOPWORDS})\n",
    "    new_freqs = {word:freq for (word,freq) in freqs.items() if word not in STOPWORDS}\n",
    "    return new_freqs\n",
    "df = clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(stopwords=STOPWORDS,height=1000,width=2000).generate_from_text(''.join(df['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfreqs.pop(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = re.compile(r\"[\\n,!\\?\\’'\\+:\\\"\\.\\$&@#/\\(\\)\\[\\]\\|\\{\\}]\")\n",
    "plt.figure(figsize=(8,5),dpi=200)\n",
    "plt.axis('off')\n",
    "plt.imshow(cloud,interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5),dpi=400)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cloud,interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_length'] = df['body'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['body_length']>500]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doomer_df = pd.read_json(\"Data/doomer_scraped_29_10_2022.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doomer_df = doomer_df.rename({\"_type\": \"type\"}, axis=\"columns\")\n",
    "doomer_df = doomer_df.replace(to_replace=\"snscrape.modules.reddit.Submission\", value=\"post\")\n",
    "doomer_df = doomer_df.replace(to_replace=\"snscrape.modules.reddit.Comment\", value=\"comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doomer_posts = doomer_df[doomer_df[\"type\"] == \"post\"]\n",
    "doomer_comments = doomer_df[doomer_df[\"type\"] == \"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doomer_posts = doomer_posts.dropna(subset=['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doomer_comments.assign(text_len=doomer_comments['body'].astype(str).map(len))\n",
    "doomer_posts.assign(text_len=doomer_posts['selftext'].astype(str).map(len))\n",
    "\n",
    "doomer_df = pd.concat([doomer_posts, doomer_comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>parentId</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>link</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>post</td>\n",
       "      <td>Fuck_Doomer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-30 08:04:25+00:00</td>\n",
       "      <td>t3_yh8k5g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/yh8k5...</td>\n",
       "      <td>None</td>\n",
       "      <td>**Hello guys :D - Before i start this text, i ...</td>\n",
       "      <td>A little jorney into the life of a Doomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>post</td>\n",
       "      <td>DonovanPeredo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-30 07:02:07+00:00</td>\n",
       "      <td>t3_yh7amo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/yh7am...</td>\n",
       "      <td>None</td>\n",
       "      <td>I have a problem and I would use a different p...</td>\n",
       "      <td>I need an advise please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>post</td>\n",
       "      <td>Alex_DK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-30 05:29:02+00:00</td>\n",
       "      <td>t3_yh5igs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/yh5ig...</td>\n",
       "      <td>None</td>\n",
       "      <td>Just lost one of my absolute favorite music ar...</td>\n",
       "      <td>Loss of an artist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>post</td>\n",
       "      <td>SoldierSam1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-30 04:44:43+00:00</td>\n",
       "      <td>t3_yh4r5q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/yh4r5...</td>\n",
       "      <td>None</td>\n",
       "      <td>I live in Phoenix and crime has gotten worse &amp;...</td>\n",
       "      <td>My City Is Hell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>post</td>\n",
       "      <td>MontiacMcgee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-30 04:40:44+00:00</td>\n",
       "      <td>t3_yh4ony</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/yh4on...</td>\n",
       "      <td>None</td>\n",
       "      <td>END IT END IT END IT\\n\\nYOUR IN FUCKING HELL J...</td>\n",
       "      <td>JUST FUCKING END IT ALREADY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>comment</td>\n",
       "      <td>french_doomer</td>\n",
       "      <td>no... sadly</td>\n",
       "      <td>2022-09-26 20:48:41+00:00</td>\n",
       "      <td>t1_iq0ptm3</td>\n",
       "      <td>t1_iq0i3mi</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/xosrg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>comment</td>\n",
       "      <td>L0tt1ce</td>\n",
       "      <td>One of the reasons that post-apocalyptic ficti...</td>\n",
       "      <td>2022-09-26 20:36:51+00:00</td>\n",
       "      <td>t1_iq0nxzp</td>\n",
       "      <td>t3_xou2i8</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/xou2i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>comment</td>\n",
       "      <td>french_doomer</td>\n",
       "      <td>you ave the same problem than me i think, we a...</td>\n",
       "      <td>2022-09-26 20:16:52+00:00</td>\n",
       "      <td>t1_iq0kr39</td>\n",
       "      <td>t3_xol0kj</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/xol0k...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>comment</td>\n",
       "      <td>doomer-driver</td>\n",
       "      <td>Literally me</td>\n",
       "      <td>2022-09-26 20:12:11+00:00</td>\n",
       "      <td>t1_iq0k0d5</td>\n",
       "      <td>t3_xo6koa</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/xo6ko...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>comment</td>\n",
       "      <td>pickletravis</td>\n",
       "      <td>I'd like to write a movie one day</td>\n",
       "      <td>2022-09-26 20:09:27+00:00</td>\n",
       "      <td>t1_iq0jl5e</td>\n",
       "      <td>t3_xo9s7o</td>\n",
       "      <td>doomer</td>\n",
       "      <td>https://old.reddit.com/r/doomer/comments/xo9s7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6832 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         type         author  \\\n",
       "34       post    Fuck_Doomer   \n",
       "41       post  DonovanPeredo   \n",
       "47       post        Alex_DK   \n",
       "51       post    SoldierSam1   \n",
       "53       post   MontiacMcgee   \n",
       "...       ...            ...   \n",
       "7038  comment  french_doomer   \n",
       "7039  comment        L0tt1ce   \n",
       "7040  comment  french_doomer   \n",
       "7041  comment  doomer-driver   \n",
       "7042  comment   pickletravis   \n",
       "\n",
       "                                                   body  \\\n",
       "34                                                  NaN   \n",
       "41                                                  NaN   \n",
       "47                                                  NaN   \n",
       "51                                                  NaN   \n",
       "53                                                  NaN   \n",
       "...                                                 ...   \n",
       "7038                                        no... sadly   \n",
       "7039  One of the reasons that post-apocalyptic ficti...   \n",
       "7040  you ave the same problem than me i think, we a...   \n",
       "7041                                       Literally me   \n",
       "7042                  I'd like to write a movie one day   \n",
       "\n",
       "                          date          id    parentId subreddit  \\\n",
       "34   2022-10-30 08:04:25+00:00   t3_yh8k5g         NaN    doomer   \n",
       "41   2022-10-30 07:02:07+00:00   t3_yh7amo         NaN    doomer   \n",
       "47   2022-10-30 05:29:02+00:00   t3_yh5igs         NaN    doomer   \n",
       "51   2022-10-30 04:44:43+00:00   t3_yh4r5q         NaN    doomer   \n",
       "53   2022-10-30 04:40:44+00:00   t3_yh4ony         NaN    doomer   \n",
       "...                        ...         ...         ...       ...   \n",
       "7038 2022-09-26 20:48:41+00:00  t1_iq0ptm3  t1_iq0i3mi    doomer   \n",
       "7039 2022-09-26 20:36:51+00:00  t1_iq0nxzp   t3_xou2i8    doomer   \n",
       "7040 2022-09-26 20:16:52+00:00  t1_iq0kr39   t3_xol0kj    doomer   \n",
       "7041 2022-09-26 20:12:11+00:00  t1_iq0k0d5   t3_xo6koa    doomer   \n",
       "7042 2022-09-26 20:09:27+00:00  t1_iq0jl5e   t3_xo9s7o    doomer   \n",
       "\n",
       "                                                    url  link  \\\n",
       "34    https://old.reddit.com/r/doomer/comments/yh8k5...  None   \n",
       "41    https://old.reddit.com/r/doomer/comments/yh7am...  None   \n",
       "47    https://old.reddit.com/r/doomer/comments/yh5ig...  None   \n",
       "51    https://old.reddit.com/r/doomer/comments/yh4r5...  None   \n",
       "53    https://old.reddit.com/r/doomer/comments/yh4on...  None   \n",
       "...                                                 ...   ...   \n",
       "7038  https://old.reddit.com/r/doomer/comments/xosrg...   NaN   \n",
       "7039  https://old.reddit.com/r/doomer/comments/xou2i...   NaN   \n",
       "7040  https://old.reddit.com/r/doomer/comments/xol0k...   NaN   \n",
       "7041  https://old.reddit.com/r/doomer/comments/xo6ko...   NaN   \n",
       "7042  https://old.reddit.com/r/doomer/comments/xo9s7...   NaN   \n",
       "\n",
       "                                               selftext  \\\n",
       "34    **Hello guys :D - Before i start this text, i ...   \n",
       "41    I have a problem and I would use a different p...   \n",
       "47    Just lost one of my absolute favorite music ar...   \n",
       "51    I live in Phoenix and crime has gotten worse &...   \n",
       "53    END IT END IT END IT\\n\\nYOUR IN FUCKING HELL J...   \n",
       "...                                                 ...   \n",
       "7038                                                NaN   \n",
       "7039                                                NaN   \n",
       "7040                                                NaN   \n",
       "7041                                                NaN   \n",
       "7042                                                NaN   \n",
       "\n",
       "                                          title  \n",
       "34    A little jorney into the life of a Doomer  \n",
       "41                      I need an advise please  \n",
       "47                           Loss of an artist.  \n",
       "51                              My City Is Hell  \n",
       "53                  JUST FUCKING END IT ALREADY  \n",
       "...                                         ...  \n",
       "7038                                        NaN  \n",
       "7039                                        NaN  \n",
       "7040                                        NaN  \n",
       "7041                                        NaN  \n",
       "7042                                        NaN  \n",
       "\n",
       "[6832 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doomer_df['te']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['text_len'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ave_txt_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdoomer_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_len\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      2\u001b[0m shortest_txt_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(doomer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_len\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      3\u001b[0m longest_txt_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(doomer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_len\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scraping/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scraping/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/scraping/lib/python3.9/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['text_len'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "ave_txt_len = int(doomer_df[['text_len']].mean(axis=0))\n",
    "shortest_txt_len = int(min(doomer_df['text_len']))\n",
    "longest_txt_len = int(max(doomer_df['text_len']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2 = doomer_df['text_len'].plot(kind='kde',\n",
    "    title=\"Distribution of Comment Length\",\n",
    "    xlabel='Comment Length',\n",
    "    xlim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely_comments = doomer_comments[doomer_comments['body'].str.contains('lonely')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely_posts = doomer_posts[doomer_posts['selftext'].astype(str).str.contains('lonely')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely_posts.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely = re.compile(\".{40}lonely.{40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(Counter(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and        73\n",
       "I          49\n",
       "to         49\n",
       "her        44\n",
       "a          35\n",
       "she        28\n",
       "was        27\n",
       "the        26\n",
       "in         21\n",
       "that       14\n",
       "being      14\n",
       "with       14\n",
       "for        14\n",
       "time       13\n",
       "it         12\n",
       "me         12\n",
       "be         11\n",
       "of         11\n",
       "had        11\n",
       "She        11\n",
       "at         11\n",
       "is         10\n",
       "talking    10\n",
       "this        9\n",
       "all         9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nlargest(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'To': 1,\n",
       "         'explain': 1,\n",
       "         'my': 4,\n",
       "         'story': 2,\n",
       "         'I': 49,\n",
       "         'will': 1,\n",
       "         'start': 1,\n",
       "         'from': 2,\n",
       "         'the': 26,\n",
       "         'beginning.': 1,\n",
       "         'met': 4,\n",
       "         'a': 35,\n",
       "         'girl': 4,\n",
       "         'online': 4,\n",
       "         'and': 73,\n",
       "         'we': 7,\n",
       "         'really': 7,\n",
       "         'hit': 4,\n",
       "         'it': 12,\n",
       "         'off.': 1,\n",
       "         'know': 6,\n",
       "         'meeting': 2,\n",
       "         'girls': 1,\n",
       "         'is': 10,\n",
       "         'considered': 1,\n",
       "         'cringy': 1,\n",
       "         'pathetic': 1,\n",
       "         'but': 3,\n",
       "         'have': 6,\n",
       "         'mental': 1,\n",
       "         'impairment.': 1,\n",
       "         'Aspergers': 1,\n",
       "         'disorder': 2,\n",
       "         'which': 2,\n",
       "         'basically': 3,\n",
       "         'condition': 1,\n",
       "         'that': 14,\n",
       "         'makes': 1,\n",
       "         'you': 2,\n",
       "         'hard': 3,\n",
       "         'time': 13,\n",
       "         'socialising': 1,\n",
       "         'being': 14,\n",
       "         'comfortable': 1,\n",
       "         'around': 2,\n",
       "         'others.': 1,\n",
       "         'So': 2,\n",
       "         'to': 49,\n",
       "         'finally': 1,\n",
       "         'be': 11,\n",
       "         'able': 2,\n",
       "         'of': 11,\n",
       "         'with': 14,\n",
       "         'looked': 2,\n",
       "         'very': 1,\n",
       "         'attractive': 1,\n",
       "         'me': 12,\n",
       "         'easy': 2,\n",
       "         'talk': 2,\n",
       "         'felt': 2,\n",
       "         'nice.': 1,\n",
       "         'We': 2,\n",
       "         'things': 2,\n",
       "         'off': 3,\n",
       "         'so': 4,\n",
       "         'well': 1,\n",
       "         'decide': 2,\n",
       "         'in': 21,\n",
       "         'relationship': 2,\n",
       "         'together': 1,\n",
       "         'decided': 2,\n",
       "         'where': 5,\n",
       "         'love': 5,\n",
       "         'each': 2,\n",
       "         'other.': 2,\n",
       "         'Later': 1,\n",
       "         'discovered': 3,\n",
       "         'she': 28,\n",
       "         'was': 27,\n",
       "         'rehab': 2,\n",
       "         'had': 11,\n",
       "         'heroin': 6,\n",
       "         'addiction': 3,\n",
       "         'kept': 2,\n",
       "         'secret': 1,\n",
       "         'for': 14,\n",
       "         'awhile': 2,\n",
       "         'before': 5,\n",
       "         'deciding': 1,\n",
       "         'tell': 1,\n",
       "         'me.': 3,\n",
       "         'this': 9,\n",
       "         'dark': 1,\n",
       "         'past': 2,\n",
       "         'What': 1,\n",
       "         'liked': 2,\n",
       "         'hearing': 1,\n",
       "         'never': 6,\n",
       "         'cheated': 3,\n",
       "         'on': 7,\n",
       "         'any': 2,\n",
       "         'her': 44,\n",
       "         'previous': 2,\n",
       "         'boyfriends': 2,\n",
       "         'low': 1,\n",
       "         'body': 1,\n",
       "         'count': 1,\n",
       "         'especially': 2,\n",
       "         'someone': 2,\n",
       "         'age.': 1,\n",
       "         'fell': 1,\n",
       "         'downplayed': 1,\n",
       "         'seriousness': 1,\n",
       "         'allowed': 1,\n",
       "         'myself': 2,\n",
       "         'think': 2,\n",
       "         'abusive': 1,\n",
       "         'toxic': 1,\n",
       "         'relationships': 3,\n",
       "         'only': 6,\n",
       "         'cause': 1,\n",
       "         'lead': 1,\n",
       "         'down': 1,\n",
       "         'path.': 1,\n",
       "         'thought': 1,\n",
       "         'if': 1,\n",
       "         'treated': 1,\n",
       "         'right': 2,\n",
       "         'could': 2,\n",
       "         'change': 1,\n",
       "         'her.': 3,\n",
       "         'She': 11,\n",
       "         'crazy': 1,\n",
       "         'ass': 1,\n",
       "         'mom': 1,\n",
       "         'yelled': 1,\n",
       "         'at': 11,\n",
       "         'all': 9,\n",
       "         \"I'm\": 2,\n",
       "         '100%': 1,\n",
       "         'sure': 1,\n",
       "         'he': 9,\n",
       "         'borderline': 1,\n",
       "         'personality': 1,\n",
       "         'dad': 1,\n",
       "         'life': 3,\n",
       "         'growing': 1,\n",
       "         'up': 3,\n",
       "         'meth': 1,\n",
       "         'more': 2,\n",
       "         'important': 1,\n",
       "         'ate': 1,\n",
       "         'soul': 2,\n",
       "         'as': 6,\n",
       "         'wanted': 3,\n",
       "         'father': 1,\n",
       "         'life.': 3,\n",
       "         'Her': 1,\n",
       "         'first': 3,\n",
       "         'boyfriend': 1,\n",
       "         'rejected': 2,\n",
       "         'said': 1,\n",
       "         \"didn't\": 7,\n",
       "         'like': 7,\n",
       "         'body.': 1,\n",
       "         'This': 1,\n",
       "         'nerdy': 1,\n",
       "         'guy': 8,\n",
       "         'who': 2,\n",
       "         'played': 1,\n",
       "         'chess': 1,\n",
       "         'job': 3,\n",
       "         'do': 3,\n",
       "         'drugs.': 1,\n",
       "         'When': 1,\n",
       "         'destroyed': 1,\n",
       "         'confidence': 2,\n",
       "         'eventually': 1,\n",
       "         'led': 2,\n",
       "         'getting': 2,\n",
       "         'drug': 3,\n",
       "         'addict.': 3,\n",
       "         'Long': 1,\n",
       "         'short': 1,\n",
       "         'iv': 2,\n",
       "         'addict': 2,\n",
       "         'over': 1,\n",
       "         '10': 1,\n",
       "         'years': 1,\n",
       "         '(I': 1,\n",
       "         'originally': 1,\n",
       "         'first).': 1,\n",
       "         'Anyways': 1,\n",
       "         'after': 5,\n",
       "         'about': 6,\n",
       "         'month': 1,\n",
       "         'talking': 10,\n",
       "         'are': 1,\n",
       "         'now': 3,\n",
       "         'together.': 2,\n",
       "         'everyday': 1,\n",
       "         'keep': 2,\n",
       "         'company': 1,\n",
       "         'via': 1,\n",
       "         'text': 1,\n",
       "         \"it's\": 1,\n",
       "         'unable': 2,\n",
       "         'leave': 1,\n",
       "         'building': 1,\n",
       "         'court': 1,\n",
       "         'ordered': 1,\n",
       "         'there.': 1,\n",
       "         'expressed': 1,\n",
       "         'interested': 1,\n",
       "         'confessing': 1,\n",
       "         'But': 2,\n",
       "         'one': 6,\n",
       "         'day': 1,\n",
       "         'went': 1,\n",
       "         'into': 2,\n",
       "         'apps': 1,\n",
       "         'phone': 2,\n",
       "         'saw': 1,\n",
       "         'immediatly': 1,\n",
       "         'sexual': 7,\n",
       "         'finds': 1,\n",
       "         'some': 5,\n",
       "         'just': 9,\n",
       "         'started': 2,\n",
       "         '\"saying': 1,\n",
       "         'wants': 3,\n",
       "         'lick': 1,\n",
       "         'his': 2,\n",
       "         '🥎⚽🏐🏀🎱': 1,\n",
       "         'suck': 1,\n",
       "         '🐓.': 1,\n",
       "         'extreme': 2,\n",
       "         'betrayal': 1,\n",
       "         'lied': 2,\n",
       "         'used': 3,\n",
       "         'perusing': 1,\n",
       "         'bought': 1,\n",
       "         'chocolates': 1,\n",
       "         'did': 2,\n",
       "         'other': 1,\n",
       "         'nice': 1,\n",
       "         'make': 2,\n",
       "         'happy.': 1,\n",
       "         'talked': 1,\n",
       "         'daily': 2,\n",
       "         'hours': 2,\n",
       "         'times': 1,\n",
       "         'everyday.': 1,\n",
       "         'How': 3,\n",
       "         'can': 2,\n",
       "         'put': 2,\n",
       "         'much': 3,\n",
       "         'effort': 2,\n",
       "         'throw': 1,\n",
       "         'away': 4,\n",
       "         'app?': 2,\n",
       "         'figured': 1,\n",
       "         'out': 3,\n",
       "         'why.': 1,\n",
       "         'turned': 1,\n",
       "         'by': 2,\n",
       "         'fact': 1,\n",
       "         'also': 1,\n",
       "         'heroin.': 1,\n",
       "         'The': 1,\n",
       "         'nice,': 1,\n",
       "         'flirty,': 1,\n",
       "         'affectionate,': 1,\n",
       "         'towards': 1,\n",
       "         'until': 1,\n",
       "         'was.': 1,\n",
       "         'straight': 1,\n",
       "         'finding': 2,\n",
       "         \"It's\": 1,\n",
       "         'funny': 1,\n",
       "         'because': 3,\n",
       "         'tried': 2,\n",
       "         'beginning': 1,\n",
       "         'acted': 1,\n",
       "         'inappropriate': 2,\n",
       "         'away.': 1,\n",
       "         'In': 1,\n",
       "         'chat': 1,\n",
       "         'him': 5,\n",
       "         'how': 3,\n",
       "         'needed': 1,\n",
       "         'steady': 1,\n",
       "         '🐓': 1,\n",
       "         'continued': 1,\n",
       "         'conversation': 3,\n",
       "         'him.': 1,\n",
       "         'losses': 1,\n",
       "         'interest': 1,\n",
       "         'found': 1,\n",
       "         'bi': 1,\n",
       "         'likes': 1,\n",
       "         'intimate': 1,\n",
       "         'men': 2,\n",
       "         'woman.': 1,\n",
       "         'again': 1,\n",
       "         '3': 3,\n",
       "         'days': 2,\n",
       "         'gonna': 1,\n",
       "         'meet': 2,\n",
       "         'real': 3,\n",
       "         'told': 3,\n",
       "         'knew': 2,\n",
       "         'few': 1,\n",
       "         'months': 2,\n",
       "         'back': 1,\n",
       "         'same': 2,\n",
       "         'even': 1,\n",
       "         'what': 1,\n",
       "         'like.': 1,\n",
       "         'stopped': 3,\n",
       "         'when': 5,\n",
       "         'doing': 1,\n",
       "         'it.': 1,\n",
       "         'apologized': 1,\n",
       "         'restart': 1,\n",
       "         'meeted': 1,\n",
       "         'am': 2,\n",
       "         'suppose': 2,\n",
       "         'feel': 9,\n",
       "         'confident': 1,\n",
       "         'believe': 2,\n",
       "         'woman': 4,\n",
       "         'actually': 1,\n",
       "         \"don't\": 1,\n",
       "         'want': 2,\n",
       "         'somebody': 3,\n",
       "         'else?': 1,\n",
       "         'choice.': 2,\n",
       "         'always': 1,\n",
       "         'loved': 3,\n",
       "         'nobody': 3,\n",
       "         'else': 1,\n",
       "         'spent': 1,\n",
       "         'alot': 1,\n",
       "         'confessed': 1,\n",
       "         'bisexual': 1,\n",
       "         'lived': 1,\n",
       "         'far': 1,\n",
       "         'another': 1,\n",
       "         'state.': 1,\n",
       "         'would': 3,\n",
       "         'blew': 1,\n",
       "         'little': 1,\n",
       "         'days.': 1,\n",
       "         'maybe': 1,\n",
       "         'last': 2,\n",
       "         'stick': 1,\n",
       "         'dumb': 1,\n",
       "         'putting': 1,\n",
       "         'effort.': 1,\n",
       "         'Just': 1,\n",
       "         'clarify': 1,\n",
       "         'working': 1,\n",
       "         'still': 1,\n",
       "         'there': 3,\n",
       "         'addiction.': 1,\n",
       "         'bit': 1,\n",
       "         'darker': 1,\n",
       "         'forever': 1,\n",
       "         \"isn't\": 1,\n",
       "         'real.': 1,\n",
       "         \"You're\": 1,\n",
       "         'distraction': 2,\n",
       "         'while': 1,\n",
       "         'reject': 1,\n",
       "         'purpose': 1,\n",
       "         'pain': 2,\n",
       "         'world.': 2,\n",
       "         'look': 2,\n",
       "         'lies,': 1,\n",
       "         'betrayal,': 1,\n",
       "         'used.': 1,\n",
       "         'My': 1,\n",
       "         'feels': 1,\n",
       "         'meaningless.': 1,\n",
       "         'All': 1,\n",
       "         'work,eat,': 1,\n",
       "         'sleep,': 1,\n",
       "         'spend': 1,\n",
       "         'periods': 1,\n",
       "         'alone.': 1,\n",
       "         'feeling': 1,\n",
       "         'going': 1,\n",
       "         'support': 1,\n",
       "         'special': 1,\n",
       "         'work': 1,\n",
       "         'them': 1,\n",
       "         'grow': 1,\n",
       "         'antisocial': 1,\n",
       "         'or': 2,\n",
       "         'friends...': 1,\n",
       "         'condition.': 1,\n",
       "         'dead': 1,\n",
       "         'inside': 1,\n",
       "         'broken.': 1,\n",
       "         'no': 4,\n",
       "         'future': 1,\n",
       "         'current': 1,\n",
       "         'purpose.': 1,\n",
       "         'Life': 1,\n",
       "         'meaningless': 1,\n",
       "         'suffering': 1,\n",
       "         'abused': 1,\n",
       "         'others': 1,\n",
       "         'truthfully': 1,\n",
       "         'purity,': 1,\n",
       "         'honesty.': 1,\n",
       "         'It': 1,\n",
       "         'lie': 1,\n",
       "         'truth': 1,\n",
       "         'me,': 2,\n",
       "         'manipulated': 1,\n",
       "         'pretended': 1,\n",
       "         'not.': 1,\n",
       "         'rock': 2,\n",
       "         'bottom,': 1,\n",
       "         'addict,': 1,\n",
       "         'thief,': 1,\n",
       "         'lay,': 1,\n",
       "         'ever,': 1,\n",
       "         'car,': 1,\n",
       "         'living': 1,\n",
       "         'then': 1,\n",
       "         'anywhere.': 1,\n",
       "         'good': 1,\n",
       "         'bottom': 1,\n",
       "         \"can't\": 1,\n",
       "         'honest,': 1,\n",
       "         'loyal,': 1,\n",
       "         'truthful': 1,\n",
       "         '🌬️': 1,\n",
       "         'texting': 1,\n",
       "         'herself': 1,\n",
       "         'all.': 1,\n",
       "         'why': 1,\n",
       "         'loyal': 1,\n",
       "         'ex': 1,\n",
       "         'showed': 1,\n",
       "         'symptoms': 1,\n",
       "         'me?': 1,\n",
       "         'way': 1,\n",
       "         'due': 1,\n",
       "         'lies': 1,\n",
       "         'manipulation': 1,\n",
       "         'lieing': 1,\n",
       "         'they': 2,\n",
       "         '\"love': 1,\n",
       "         'me\"': 1,\n",
       "         '\"want': 1,\n",
       "         'else\"': 1,\n",
       "         'spending': 1,\n",
       "         'many': 1,\n",
       "         'lonely': 1,\n",
       "         'locked': 1,\n",
       "         'shi*ty': 1,\n",
       "         'rehab.': 1,\n",
       "         'Fu*k': 1,\n",
       "         'didnt': 1,\n",
       "         'deserve': 1,\n",
       "         'that.': 1})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To',\n",
       " 'explain',\n",
       " 'my',\n",
       " 'story',\n",
       " 'I',\n",
       " 'will',\n",
       " 'start',\n",
       " 'from',\n",
       " 'the',\n",
       " 'beginning.',\n",
       " 'I',\n",
       " 'met',\n",
       " 'a',\n",
       " 'girl',\n",
       " 'online',\n",
       " 'and',\n",
       " 'we',\n",
       " 'really',\n",
       " 'hit',\n",
       " 'it',\n",
       " 'off.',\n",
       " 'I',\n",
       " 'know',\n",
       " 'meeting',\n",
       " 'girls',\n",
       " 'online',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'cringy',\n",
       " 'and',\n",
       " 'pathetic',\n",
       " 'but',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'mental',\n",
       " 'impairment.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'Aspergers',\n",
       " 'disorder',\n",
       " 'which',\n",
       " 'is',\n",
       " 'basically',\n",
       " 'a',\n",
       " 'condition',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'really',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'socialising',\n",
       " 'and',\n",
       " 'being',\n",
       " 'comfortable',\n",
       " 'around',\n",
       " 'others.',\n",
       " 'So',\n",
       " 'to',\n",
       " 'finally',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'hit',\n",
       " 'it',\n",
       " 'of',\n",
       " 'with',\n",
       " 'a',\n",
       " 'girl',\n",
       " 'that',\n",
       " 'looked',\n",
       " 'very',\n",
       " 'attractive',\n",
       " 'to',\n",
       " 'me',\n",
       " 'and',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'felt',\n",
       " 'really',\n",
       " 'nice.',\n",
       " 'We',\n",
       " 'hit',\n",
       " 'things',\n",
       " 'off',\n",
       " 'so',\n",
       " 'well',\n",
       " 'that',\n",
       " 'we',\n",
       " 'decide',\n",
       " 'to',\n",
       " 'be',\n",
       " 'in',\n",
       " 'a',\n",
       " 'online',\n",
       " 'relationship',\n",
       " 'together',\n",
       " 'and',\n",
       " 'decided',\n",
       " 'we',\n",
       " 'where',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other.',\n",
       " 'Later',\n",
       " 'I',\n",
       " 'discovered',\n",
       " 'she',\n",
       " 'was',\n",
       " 'in',\n",
       " 'a',\n",
       " 'rehab',\n",
       " 'and',\n",
       " 'had',\n",
       " 'a',\n",
       " 'heroin',\n",
       " 'addiction',\n",
       " 'which',\n",
       " 'she',\n",
       " 'kept',\n",
       " 'a',\n",
       " 'secret',\n",
       " 'for',\n",
       " 'awhile',\n",
       " 'before',\n",
       " 'deciding',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'me.',\n",
       " 'I',\n",
       " 'discovered',\n",
       " 'this',\n",
       " 'girl',\n",
       " 'had',\n",
       " 'a',\n",
       " 'dark',\n",
       " 'past',\n",
       " 'before',\n",
       " 'meeting',\n",
       " 'me.',\n",
       " 'What',\n",
       " 'I',\n",
       " 'liked',\n",
       " 'hearing',\n",
       " 'was',\n",
       " 'that',\n",
       " 'she',\n",
       " 'never',\n",
       " 'cheated',\n",
       " 'on',\n",
       " 'any',\n",
       " 'of',\n",
       " 'her',\n",
       " 'previous',\n",
       " 'boyfriends',\n",
       " 'and',\n",
       " 'had',\n",
       " 'a',\n",
       " 'low',\n",
       " 'body',\n",
       " 'count',\n",
       " 'especially',\n",
       " 'for',\n",
       " 'someone',\n",
       " 'her',\n",
       " 'age.',\n",
       " 'I',\n",
       " 'fell',\n",
       " 'really',\n",
       " 'hard',\n",
       " 'for',\n",
       " 'her',\n",
       " 'before',\n",
       " 'I',\n",
       " 'discovered',\n",
       " 'she',\n",
       " 'had',\n",
       " 'a',\n",
       " 'heroin',\n",
       " 'addiction',\n",
       " 'and',\n",
       " 'I',\n",
       " 'downplayed',\n",
       " 'the',\n",
       " 'seriousness',\n",
       " 'of',\n",
       " 'her',\n",
       " 'addiction',\n",
       " 'and',\n",
       " 'allowed',\n",
       " 'myself',\n",
       " 'to',\n",
       " 'think',\n",
       " 'her',\n",
       " 'abusive',\n",
       " 'and',\n",
       " 'toxic',\n",
       " 'relationships',\n",
       " 'of',\n",
       " 'her',\n",
       " 'past',\n",
       " 'where',\n",
       " 'the',\n",
       " 'only',\n",
       " 'cause',\n",
       " 'that',\n",
       " 'lead',\n",
       " 'her',\n",
       " 'down',\n",
       " 'this',\n",
       " 'path.',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'if',\n",
       " 'I',\n",
       " 'treated',\n",
       " 'her',\n",
       " 'right',\n",
       " 'I',\n",
       " 'could',\n",
       " 'change',\n",
       " 'her.',\n",
       " 'She',\n",
       " 'had',\n",
       " 'a',\n",
       " 'crazy',\n",
       " 'ass',\n",
       " 'mom',\n",
       " 'that',\n",
       " 'yelled',\n",
       " 'at',\n",
       " 'her',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'and',\n",
       " \"I'm\",\n",
       " '100%',\n",
       " 'sure',\n",
       " 'he',\n",
       " 'had',\n",
       " 'borderline',\n",
       " 'personality',\n",
       " 'disorder',\n",
       " 'and',\n",
       " 'her',\n",
       " 'dad',\n",
       " 'was',\n",
       " 'never',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " 'growing',\n",
       " 'up',\n",
       " 'and',\n",
       " 'decided',\n",
       " 'meth',\n",
       " 'was',\n",
       " 'more',\n",
       " 'important',\n",
       " 'and',\n",
       " 'it',\n",
       " 'ate',\n",
       " 'at',\n",
       " 'her',\n",
       " 'soul',\n",
       " 'as',\n",
       " 'she',\n",
       " 'wanted',\n",
       " 'her',\n",
       " 'father',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life.',\n",
       " 'Her',\n",
       " 'first',\n",
       " 'boyfriend',\n",
       " 'rejected',\n",
       " 'her',\n",
       " 'and',\n",
       " 'said',\n",
       " 'he',\n",
       " \"didn't\",\n",
       " 'like',\n",
       " 'her',\n",
       " 'body.',\n",
       " 'This',\n",
       " 'was',\n",
       " 'a',\n",
       " 'nerdy',\n",
       " 'guy',\n",
       " 'who',\n",
       " 'played',\n",
       " 'chess',\n",
       " 'and',\n",
       " 'had',\n",
       " 'a',\n",
       " 'job',\n",
       " 'and',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'drugs.',\n",
       " 'When',\n",
       " 'he',\n",
       " 'rejected',\n",
       " 'her',\n",
       " 'it',\n",
       " 'destroyed',\n",
       " 'her',\n",
       " 'confidence',\n",
       " 'and',\n",
       " 'it',\n",
       " 'eventually',\n",
       " 'led',\n",
       " 'to',\n",
       " 'her',\n",
       " 'getting',\n",
       " 'with',\n",
       " 'a',\n",
       " 'drug',\n",
       " 'addict.',\n",
       " 'Long',\n",
       " 'story',\n",
       " 'short',\n",
       " 'it',\n",
       " 'led',\n",
       " 'to',\n",
       " 'being',\n",
       " 'a',\n",
       " 'drug',\n",
       " 'iv',\n",
       " 'addict',\n",
       " 'for',\n",
       " 'over',\n",
       " '10',\n",
       " 'years',\n",
       " '(I',\n",
       " 'originally',\n",
       " \"didn't\",\n",
       " 'know',\n",
       " 'this',\n",
       " 'at',\n",
       " 'first).',\n",
       " 'Anyways',\n",
       " 'after',\n",
       " 'about',\n",
       " 'a',\n",
       " 'month',\n",
       " 'of',\n",
       " 'talking',\n",
       " 'we',\n",
       " 'hit',\n",
       " 'it',\n",
       " 'off',\n",
       " 'and',\n",
       " 'decide',\n",
       " 'that',\n",
       " 'we',\n",
       " 'are',\n",
       " 'now',\n",
       " 'in',\n",
       " 'a',\n",
       " 'relationship',\n",
       " 'together.',\n",
       " 'I',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'her',\n",
       " 'everyday',\n",
       " 'and',\n",
       " 'keep',\n",
       " 'her',\n",
       " 'company',\n",
       " 'via',\n",
       " 'text',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'as',\n",
       " \"it's\",\n",
       " 'all',\n",
       " 'we',\n",
       " 'could',\n",
       " 'do',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'as',\n",
       " 'she',\n",
       " 'was',\n",
       " 'basically',\n",
       " 'unable',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'the',\n",
       " 'building',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'court',\n",
       " 'ordered',\n",
       " 'for',\n",
       " 'her',\n",
       " 'to',\n",
       " 'be',\n",
       " 'there.',\n",
       " 'She',\n",
       " 'expressed',\n",
       " 'being',\n",
       " 'really',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'me',\n",
       " 'and',\n",
       " 'confessing',\n",
       " 'her',\n",
       " 'love',\n",
       " 'for',\n",
       " 'me.',\n",
       " 'But',\n",
       " 'one',\n",
       " 'day',\n",
       " 'I',\n",
       " 'went',\n",
       " 'into',\n",
       " 'one',\n",
       " 'of',\n",
       " 'her',\n",
       " 'apps',\n",
       " 'on',\n",
       " 'her',\n",
       " 'phone',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'her',\n",
       " 'immediatly',\n",
       " 'being',\n",
       " 'sexual',\n",
       " 'after',\n",
       " 'she',\n",
       " 'finds',\n",
       " 'some',\n",
       " 'guy',\n",
       " 'she',\n",
       " 'just',\n",
       " 'started',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'online',\n",
       " 'is',\n",
       " 'a',\n",
       " 'heroin',\n",
       " 'addict.',\n",
       " '\"saying',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'lick',\n",
       " 'his',\n",
       " '🥎⚽🏐🏀🎱',\n",
       " 'and',\n",
       " 'suck',\n",
       " 'his',\n",
       " '🐓.',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'like',\n",
       " 'this',\n",
       " 'was',\n",
       " 'extreme',\n",
       " 'betrayal',\n",
       " 'and',\n",
       " 'that',\n",
       " 'I',\n",
       " 'was',\n",
       " 'being',\n",
       " 'lied',\n",
       " 'to',\n",
       " 'and',\n",
       " 'used',\n",
       " 'and',\n",
       " 'was',\n",
       " 'just',\n",
       " 'the',\n",
       " 'one',\n",
       " 'guy',\n",
       " 'that',\n",
       " 'kept',\n",
       " 'perusing',\n",
       " 'her.',\n",
       " 'I',\n",
       " 'bought',\n",
       " 'her',\n",
       " 'chocolates',\n",
       " 'and',\n",
       " 'did',\n",
       " 'other',\n",
       " 'nice',\n",
       " 'things',\n",
       " 'for',\n",
       " 'her',\n",
       " 'to',\n",
       " 'make',\n",
       " 'her',\n",
       " 'happy.',\n",
       " 'We',\n",
       " 'talked',\n",
       " 'daily',\n",
       " 'for',\n",
       " 'hours',\n",
       " 'at',\n",
       " 'times',\n",
       " 'everyday.',\n",
       " 'How',\n",
       " 'can',\n",
       " 'I',\n",
       " 'put',\n",
       " 'in',\n",
       " 'so',\n",
       " 'much',\n",
       " 'effort',\n",
       " 'and',\n",
       " 'time',\n",
       " 'into',\n",
       " 'her',\n",
       " 'and',\n",
       " 'her',\n",
       " 'being',\n",
       " 'able',\n",
       " 'to',\n",
       " 'throw',\n",
       " 'it',\n",
       " 'all',\n",
       " 'away',\n",
       " 'for',\n",
       " 'some',\n",
       " 'guy',\n",
       " 'she',\n",
       " 'just',\n",
       " 'met',\n",
       " 'on',\n",
       " 'a',\n",
       " 'phone',\n",
       " 'app?',\n",
       " 'I',\n",
       " 'figured',\n",
       " 'out',\n",
       " 'why.',\n",
       " 'She',\n",
       " 'was',\n",
       " 'turned',\n",
       " 'on',\n",
       " 'by',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'he',\n",
       " 'also',\n",
       " 'did',\n",
       " 'heroin.',\n",
       " 'The',\n",
       " 'guy',\n",
       " 'was',\n",
       " 'never',\n",
       " 'nice,',\n",
       " 'flirty,',\n",
       " 'affectionate,',\n",
       " 'sexual',\n",
       " 'towards',\n",
       " 'her',\n",
       " 'until',\n",
       " 'she',\n",
       " 'was.',\n",
       " 'She',\n",
       " 'basically',\n",
       " 'was',\n",
       " 'sexual',\n",
       " 'straight',\n",
       " 'away',\n",
       " 'after',\n",
       " 'finding',\n",
       " 'out',\n",
       " 'he',\n",
       " 'was',\n",
       " 'a',\n",
       " 'previous',\n",
       " 'heroin',\n",
       " 'addict.',\n",
       " \"It's\",\n",
       " 'funny',\n",
       " 'because',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'I',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'be',\n",
       " 'sexual',\n",
       " 'in',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'getting',\n",
       " 'to',\n",
       " 'know',\n",
       " 'her',\n",
       " 'she',\n",
       " 'acted',\n",
       " 'like',\n",
       " 'it',\n",
       " 'was',\n",
       " 'inappropriate',\n",
       " 'and',\n",
       " \"didn't\",\n",
       " 'like',\n",
       " 'me',\n",
       " 'being',\n",
       " 'sexual',\n",
       " 'with',\n",
       " 'her',\n",
       " 'right',\n",
       " 'away.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'chat',\n",
       " 'with',\n",
       " 'him',\n",
       " 'she',\n",
       " 'was',\n",
       " 'talking',\n",
       " 'about',\n",
       " 'how',\n",
       " 'much',\n",
       " 'she',\n",
       " 'needed',\n",
       " 'steady',\n",
       " '🐓',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " 'and',\n",
       " 'continued',\n",
       " 'sexual',\n",
       " 'conversation',\n",
       " 'with',\n",
       " 'him.',\n",
       " 'She',\n",
       " 'only',\n",
       " 'losses',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'the',\n",
       " 'guy',\n",
       " 'after',\n",
       " 'she',\n",
       " 'found',\n",
       " 'out',\n",
       " 'he',\n",
       " 'was',\n",
       " 'a',\n",
       " 'bi',\n",
       " 'sexual',\n",
       " 'and',\n",
       " 'likes',\n",
       " 'being',\n",
       " 'intimate',\n",
       " 'with',\n",
       " 'men',\n",
       " 'and',\n",
       " 'woman.',\n",
       " 'She',\n",
       " 'started',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'him',\n",
       " 'again',\n",
       " '3',\n",
       " 'days',\n",
       " 'before',\n",
       " 'we',\n",
       " 'where',\n",
       " 'gonna',\n",
       " 'meet',\n",
       " 'up',\n",
       " 'in',\n",
       " 'real',\n",
       " 'life.',\n",
       " 'I',\n",
       " 'told',\n",
       " 'her',\n",
       " 'I',\n",
       " 'knew',\n",
       " 'she',\n",
       " 'was',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'someone',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'back',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'she',\n",
       " 'had',\n",
       " 'that',\n",
       " 'inappropriate',\n",
       " 'conversation',\n",
       " 'with',\n",
       " 'that',\n",
       " 'guy',\n",
       " 'she',\n",
       " 'never',\n",
       " 'met',\n",
       " 'and',\n",
       " \"didn't\",\n",
       " 'even',\n",
       " 'know',\n",
       " 'what',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'like.',\n",
       " 'She',\n",
       " 'stopped',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'him',\n",
       " 'when',\n",
       " 'I',\n",
       " 'told',\n",
       " 'her',\n",
       " 'I',\n",
       " 'knew',\n",
       " 'she',\n",
       " 'was',\n",
       " 'doing',\n",
       " 'it.',\n",
       " 'She',\n",
       " 'apologized',\n",
       " 'and',\n",
       " 'stopped',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'him',\n",
       " 'for',\n",
       " 'awhile',\n",
       " 'but',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'restart',\n",
       " 'conversation',\n",
       " '3',\n",
       " 'days',\n",
       " 'before',\n",
       " 'I',\n",
       " 'meeted',\n",
       " 'up',\n",
       " 'with',\n",
       " 'her',\n",
       " 'in',\n",
       " 'real',\n",
       " 'life.',\n",
       " 'How',\n",
       " 'am',\n",
       " 'I',\n",
       " 'suppose',\n",
       " 'to',\n",
       " 'feel',\n",
       " 'confident',\n",
       " 'and',\n",
       " 'believe',\n",
       " 'woman',\n",
       " 'actually',\n",
       " 'love',\n",
       " 'me',\n",
       " 'and',\n",
       " \"don't\",\n",
       " 'want',\n",
       " 'somebody',\n",
       " 'else?',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'I',\n",
       " 'was',\n",
       " 'her',\n",
       " 'only',\n",
       " 'choice.',\n",
       " 'She',\n",
       " 'always',\n",
       " 'told',\n",
       " 'me',\n",
       " 'how',\n",
       " 'she',\n",
       " 'loved',\n",
       " 'me',\n",
       " 'and',\n",
       " 'wanted',\n",
       " 'nobody',\n",
       " 'else',\n",
       " 'and',\n",
       " 'spent',\n",
       " 'alot',\n",
       " 'of',\n",
       " 'time',\n",
       " 'daily',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other.',\n",
       " 'I',\n",
       " 'know',\n",
       " 'she',\n",
       " 'only',\n",
       " 'stopped',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'him',\n",
       " 'because',\n",
       " 'he',\n",
       " 'confessed',\n",
       " 'to',\n",
       " 'being',\n",
       " 'bisexual',\n",
       " 'and',\n",
       " 'he',\n",
       " 'lived',\n",
       " 'far',\n",
       " 'away',\n",
       " 'in',\n",
       " 'another',\n",
       " 'state.',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'she',\n",
       " 'would',\n",
       " 'have',\n",
       " 'cheated',\n",
       " 'on',\n",
       " 'me',\n",
       " 'and',\n",
       " 'blew',\n",
       " 'me',\n",
       " 'off',\n",
       " 'after',\n",
       " 'me',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'her',\n",
       " 'for',\n",
       " 'months',\n",
       " 'and',\n",
       " 'about',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'in',\n",
       " 'just',\n",
       " 'as',\n",
       " 'little',\n",
       " 'as',\n",
       " '3',\n",
       " 'days.',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'maybe',\n",
       " 'all',\n",
       " 'relationships',\n",
       " 'with',\n",
       " 'woman',\n",
       " 'is',\n",
       " 'you',\n",
       " 'where',\n",
       " 'the',\n",
       " 'last',\n",
       " 'one',\n",
       " 'to',\n",
       " 'stick',\n",
       " 'around',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'her',\n",
       " 'only',\n",
       " 'and',\n",
       " 'last',\n",
       " 'choice.',\n",
       " 'I',\n",
       " 'was',\n",
       " 'the',\n",
       " 'dumb',\n",
       " 'one',\n",
       " 'who',\n",
       " 'put',\n",
       " 'in',\n",
       " 'the',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'and',\n",
       " 'effort',\n",
       " 'and',\n",
       " 'the',\n",
       " 'only',\n",
       " 'one',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'putting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'time',\n",
       " 'and',\n",
       " 'effort.',\n",
       " 'Just',\n",
       " 'to',\n",
       " 'clarify',\n",
       " 'I',\n",
       " 'had',\n",
       " 'a',\n",
       " 'job',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'and',\n",
       " 'was',\n",
       " 'working',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'and',\n",
       " 'still',\n",
       " 'finding',\n",
       " 'away',\n",
       " 'to',\n",
       " 'be',\n",
       " 'there',\n",
       " 'for',\n",
       " 'her',\n",
       " 'and',\n",
       " \"didn't\",\n",
       " 'have',\n",
       " 'a',\n",
       " 'drug',\n",
       " 'addiction.',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'soul',\n",
       " 'is',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'darker',\n",
       " 'forever',\n",
       " 'now',\n",
       " 'and',\n",
       " 'that',\n",
       " 'love',\n",
       " \"isn't\",\n",
       " 'really',\n",
       " 'real.',\n",
       " \"You're\",\n",
       " 'just',\n",
       " 'a',\n",
       " 'distraction',\n",
       " 'while',\n",
       " 'all',\n",
       " 'the',\n",
       " 'men',\n",
       " 'she',\n",
       " 'really',\n",
       " 'wants',\n",
       " 'reject',\n",
       " 'her.',\n",
       " 'I',\n",
       " 'used',\n",
       " 'to',\n",
       " 'feel',\n",
       " 'relationships',\n",
       " 'and',\n",
       " 'being',\n",
       " 'with',\n",
       " 'a',\n",
       " 'girl',\n",
       " 'that',\n",
       " 'loved',\n",
       " 'me',\n",
       " 'would',\n",
       " 'be',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' many hours being there when they where lonely and had nobody and locked in some shi*t']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lonely.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = lonely_posts.head()['selftext'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
